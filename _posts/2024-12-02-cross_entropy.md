---
title: "交叉熵"
layout: post
date: 2024-12-02
categories: tech_coding
tags:
    - machine_learning
---

最近非常好奇交叉熵和物理学中的熵有什么联系和区别, 做了一个小小的调查. 发现原来是信息学借用了物理学的概念, 而交叉熵是直接采用了物理学之中的概念.
交叉熵（Cross-Entropy）这个名字来源于信息论中的“熵”概念，它与物理学中的熵存在一些概念上的联系，但也有显著的差异。以下是详细的解释：

---

### **1. 信息论中的熵**

在信息论中，熵（Entropy）是用来度量随机变量不确定性或信息量的概念。给定一个概率分布 $$P(x)$$，它的熵定义为：

$$
H(P) = -\sum_{x} P(x) \log P(x)
$$

熵的意义在于描述信息的平均不确定性。例如，在抛硬币中，均匀分布（公平硬币）下熵最大，而确定性分布（总是正面）下熵为零。

---

### **2. 交叉熵的定义**

交叉熵是两个概率分布之间的一种距离度量，它衡量的是一个分布 $$Q(x)$$ 对于真实分布 $$P(x)$$ 的“预测效果”。交叉熵定义为：

$$
H(P, Q) = -\sum_{x} P(x) \log Q(x)
$$

其中：
- $$P(x)$$：真实分布（目标分布）
- $$Q(x)$$：预测分布（模型输出）

交叉熵的意义在于，如果我们使用 $$Q(x)$$ 来编码由 $$P(x)$$ 产生的数据，平均编码长度会是多少。因此，它反映了预测分布 $$Q(x)$$ 偏离真实分布 $$P(x)$$ 的程度。

---

### **3. 交叉熵与信息论中的熵的关系**

交叉熵可以分解为真实熵和相对熵（Kullback-Leibler 散度）的和：

$$
H(P, Q) = H(P) + D_{KL}(P \| Q)
$$

其中：
- $$H(P)$$ 是真实分布的熵，表示最小理论编码长度（由 $$P$$ 自身决定）。
- $$D_{KL}(P \| Q)$$ 是 $$P$$ 和 $$Q$$ 之间的相对熵，表示预测分布 $$Q$$ 偏离真实分布 $$P\) 的额外代价。

因此，交叉熵结合了熵的基础概念，同时加入了对预测分布 $$Q$$ 的偏离度量。

---

### **4. 物理学中的熵**

物理学中的熵来自热力学和统计力学，描述系统的混乱程度或微观状态的数量。公式为：

$$
S = -k_B \sum_{i} p_i \ln p_i
$$

其中 $$k_B$$ 是玻尔兹曼常数，$$p_i$$u 是系统处于某一微观状态的概率。

在物理学中，熵通常被视为一个系统的无序程度或混乱程度的量度。熵增原理是热力学第二定律的核心，它告诉我们：一个孤立系统的熵总是趋向于增加，直到达到最大值，也就是系统最无序的状态。

**不可逆性：** 熵增过程是不可逆的，也就是说，一个系统从有序状态向无序状态的转变是自发的，但反过来却需要外界做功。这就像打碎一个杯子很容易，但要将碎玻璃重新拼成完整的杯子却非常困难。
为什么熵是不可逆的？

**微观粒子的随机运动：** 组成物质的微观粒子（如原子、分子）处于永不停息的无规则运动中。随着时间的推移，这些粒子越来越趋向于均匀分布，系统的有序性逐渐降低。
**宏观过程的统计性：** 宏观过程是由大量微观粒子的集体行为决定的。虽然单个粒子的运动是可逆的，但由于粒子数量巨大，宏观上的过程表现出明显的不可逆性。
**联系：**
- 信息论的熵借用了物理学中熵的思想：都是用概率来描述系统的“无序”程度。
- 信息论的熵公式形式上与统计力学的熵类似，只是信息论省略了物理单位（如 $$k_B$$）。

**区别：**
- 信息论中的熵是无量纲的，专注于概率分布对信息的描述。
- 物理学中的熵具有物理单位（如能量/温度），描述系统的热力学性质。

---

### **5. 为什么叫“交叉熵”？**

“交叉”的含义在于它涉及两个分布 $$P$$ 和 $$Q$$，并通过 $$P(x)$$ 的权重与 $$Q(x)$$ 的对数值进行交叉计算。相比单纯描述一个分布的不确定性（熵），交叉熵进一步量化了两个分布的匹配程度。

---

### **总结**

交叉熵之所以得名，是因为它继承了信息论中的熵的思想，用来度量分布之间的差异。它和物理学中的熵在本质上都反映了系统的“无序”或“不确定性”，但应用领域和具体定义不同。


