---
title: "The bitter Lesson 读后感"
layout: post
date: 2025-04-23
categories: tech_coding
tags:
    - machine_learning
    - reinforcement_learning
---



今天读了Rich Sutton的<The Bitter Lesson>,  以下是我和Gemini一起写出来的读后感.

**人工智能中的 "Bitter Lesson"：为什么 Computation 胜过人类智慧**

 经过 70 年的人工智能研究，最关键的结论是：利用 computation 的通用方法，最终都是最有效的，而且效果显著。 

**Computation 的力量**

为什么 computation 如此重要？ 这可以归结为摩尔定律——即 computation 的成本持续呈指数级下降的规律。 
虽然许多研究人员在开发人工智能时都假设 computation 的数量是固定的，但现实情况是，computation 的能力随着时间的推移而大幅增长。 
因此，虽然使用人类知识似乎是获得短期收益的捷径，但人工智能的长期成功依赖于利用不断增长的 computation。

**以人类为中心的方法的缺陷**

这里就变得复杂了。 通常需要权衡：花在试图编码人类知识上的时间，就*不是*花在开发能够利用更多 computation 的方法上的时间。 

此外，专注于人类知识可能会导致系统变得复杂，从而使其不适合通过更多的 computation 进行扩展。 

**案例分析：Computation 获胜的时刻**

作者提供了一些令人信服的例子：

* **计算机国际象棋：** 还记得深蓝击败卡斯帕罗夫吗？ 那场胜利来自于大规模的深度 search。 当时，许多国际象棋研究人员对此感到不满，因为他们更喜欢使用人类对国际象棋的理解的方法。 
   
* **计算机围棋：** 围棋领域也出现了类似的现象。 最初的努力试图融入人类知识，但最终，search 和 self-play learning 才是改变游戏规则的关键。 Self-play *learning*，就像 *search* 一样，使我们能够利用大量的 *computation*。 
   
* **语音识别：** 早期的语音识别系统依赖于人类的语言知识。 但是，统计方法，以及后来的深度 learning，使用了更多的 *computation* 和对大量数据集的 *learning*，事实证明，这些方法要优越得多。 
   
* **计算机视觉：** 最初的计算机视觉技术试图通过搜索边缘之类的东西来模仿人类视觉。  现代深度 learning，采用卷积等 *computation* 大的方法，性能超过了它们。 

**拥抱 "Bitter Lesson"**

关键的结论是什么？ 停止尝试以我们*认为*我们大脑工作的方式来编写人工智能程序。 

以下是 "Bitter Lesson" 的细分：

1.  人工智能研究人员经常试图将人类知识构建到他们的 agent 中。 
   
2.  这在短期内有所帮助。 
   
3.  但从长远来看，它会限制进步。 
   
4.  突破来自于通过 *search* 和 *learning* 来扩展 *computation*。 

这个认识可能有点 "苦涩"，因为它意味着要放弃我们最喜欢的、受人类启发的方法。 

**展望未来**

那么，我们应该从中吸取什么教训呢？

* **通用方法是关键：** 我们需要能够随着 *computation* 的持续增长而有效扩展的方法。 *Search* 和 *learning* 似乎就是这类方法。 
   
* **人类思维非常复杂：** 人类智能非常复杂。 我们应该专注于 "元方法"，使人工智能能够自行发现和学习，而不是试图对我们的理解进行硬编码。 

让我们构建能够像我们一样进行发现的人工智能 agent，而不仅仅是模仿我们已经知道的东西。 

